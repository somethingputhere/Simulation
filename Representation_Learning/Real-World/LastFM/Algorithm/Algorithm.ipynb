{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.linalg import orth\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from matplotlib.ticker import LogFormatter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.random.seed(29)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ee2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_action_set(trials, M, d, k):\n",
    "    \n",
    "    user_artists = pd.read_csv('../user_artists.dat', sep='\\t')\n",
    "\n",
    "    artist_counts = user_artists['artistID'].value_counts()\n",
    "    artists_filtered = artist_counts[artist_counts >= 30].index\n",
    "    user_artists_filtered = user_artists[user_artists['artistID'].isin(artists_filtered)]\n",
    "\n",
    "    user_counts = user_artists_filtered['userID'].value_counts()\n",
    "    users_filtered = user_counts[user_counts >= 30].index\n",
    "    user_artists_final = user_artists_filtered[user_artists_filtered['userID'].isin(users_filtered)]\n",
    "\n",
    "    rating_matrix = pd.pivot_table(user_artists_final, index = 'userID', columns = 'artistID', aggfunc = lambda x: x, fill_value = 0)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    rating_matrix = pd.DataFrame(scaler.fit_transform(rating_matrix), columns=rating_matrix.columns)\n",
    "\n",
    "    model = NMF(n_components = int(np.sqrt(d)), init = 'nndsvda', max_iter = 10000)\n",
    "    W = model.fit_transform(rating_matrix)\n",
    "    H = model.components_\n",
    "    \n",
    "    theta_true = np.eye(int(np.sqrt(d))).ravel()\n",
    "    Theta = np.tile(theta_true, (M, 1)).T[np.newaxis, :]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = M, random_state = 0).fit(H.T)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    Action_list = np.empty((1, W.shape[0], M), dtype = object)\n",
    "\n",
    "    for t in range(W.shape[0]):\n",
    "\n",
    "        for i in range(M):\n",
    "\n",
    "            size = H[:, labels == i].shape[1]\n",
    "            Action_list[0, t, i] = np.empty((size, d), dtype = object)\n",
    "\n",
    "            for ac in range(size):\n",
    "\n",
    "                temp = np.outer(W[t], H[:, labels == i][:, ac])\n",
    "                Action_list[0, t, i][ac] = temp.ravel()\n",
    "                \n",
    "    return Action_list, Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64fbb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_altgdmin(X, t, Y, C, M, d, k):\n",
    "    \n",
    "    alpha = C * np.linalg.norm(Y, 'fro') / np.sqrt(t * M)\n",
    "    Y_trunc = np.where(np.abs(Y) > alpha, 0, Y)\n",
    "    \n",
    "    Theta_0 = np.zeros((d, M))\n",
    "    \n",
    "    for i in range(M):\n",
    "        \n",
    "        Theta_0[:, i] = np.sum(X[i].dot(np.diag(Y_trunc[i])), axis=1) / t\n",
    "    \n",
    "    U_0, Sigma_0, V_0 = np.linalg.svd(Theta_0, full_matrices = False)\n",
    "    B_hat = U_0[:, :k]\n",
    "    S_k = np.zeros((k, k))\n",
    "    np.fill_diagonal(S_k, Sigma_0[:k])\n",
    "    \n",
    "    return B_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d35a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AltGD_Min(X, Y, M, k, B_hat):\n",
    "    \n",
    "    W_hat = np.zeros((k, M))\n",
    "    \n",
    "    for i in range(M):\n",
    "\n",
    "        W_hat[:, i] = np.linalg.lstsq(np.dot(X[i].T, B_hat), Y[i], rcond = None)[0]\n",
    "    \n",
    "    return W_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_Trials_ICML = []\n",
    "CR_Trials_E2TC = []\n",
    "CR_Trials_Naive = []\n",
    "d = 100\n",
    "M = 10\n",
    "k = 1\n",
    "C = 4\n",
    "R = 1\n",
    "ld = 1\n",
    "ld_0 = 1\n",
    "trials = 1\n",
    "sigma = 1e-3\n",
    "delta = 1e-3\n",
    "epoch_iter = 300\n",
    "iterations = 1000\n",
    "every_point = 25\n",
    "A, Theta = generate_action_set(trials, M, d, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29719c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the noise of reward for each iteration\n",
    "noise_list = np.random.normal(0, sigma ** 2, size = (trials, iterations, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04916dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_exploration_list = []\n",
    "\n",
    "for t in range(epoch_iter):\n",
    "    \n",
    "    temp = []\n",
    "\n",
    "    for i in range(M):\n",
    "\n",
    "        action = np.random.choice(A[0][t, i].shape[0])\n",
    "        temp.append(action)\n",
    "        \n",
    "    action_exploration_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Context_idx = np.random.choice(A.shape[1], size = iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "#     print('Trial:', T)\n",
    "    \n",
    "    action_set = A[T]\n",
    "    noise_T = noise_list[T]\n",
    "    \n",
    "    B_hat = np.zeros((d, k))\n",
    "    W_hat = np.zeros((k, M))\n",
    "    Theta_hat = B_hat.dot(W_hat)\n",
    "    \n",
    "    cumulative_regret = 0\n",
    "    cummulative_regret_list = [0]\n",
    "    \n",
    "    X = [np.empty((d, epoch_iter)) for _ in range(M)]\n",
    "    Y = [np.empty(epoch_iter) for _ in range(M)]\n",
    "    \n",
    "    for t in tqdm(range(epoch_iter), desc = 'exploration iterations'):\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            action = action_exploration_list[t][i]\n",
    "            reward = action_set[t, i][action].dot(Theta[T][:, i])\n",
    "            cumulative_regret += np.max(action_set[t, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "            X[i][:, t] = action_set[t, i][action].reshape(-1)\n",
    "            Y[i][t] = reward + noise_T[t, i]\n",
    "            \n",
    "        cummulative_regret_list.append(cumulative_regret)\n",
    "        \n",
    "    B_hat = init_altgdmin(X, epoch_iter, Y, C, M, d, k)\n",
    "    W_hat = AltGD_Min(X, Y, M, k, B_hat)\n",
    "    Theta_hat = B_hat.dot(W_hat)\n",
    "    \n",
    "    for t in tqdm(range(epoch_iter, iterations), desc = 'commit iterations'):\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            context = Context_idx[t]\n",
    "            \n",
    "            action = np.argmax(np.dot(action_set[context, i], Theta_hat[:, i]))\n",
    "            reward = action_set[context, i][action].dot(Theta[T][:, i])\n",
    "            cumulative_regret += np.max(action_set[context, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "#             action = np.argmax(np.dot(action_set[t, i], Theta_hat[:, i]))\n",
    "#             reward = action_set[t, i][action].dot(Theta[T][:, i])\n",
    "#             cumulative_regret += np.max(action_set[t, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "        cummulative_regret_list.append(cumulative_regret)\n",
    "        \n",
    "#         print('t: {} regret: {} error: {}:'.format(num, regret, error))\n",
    "\n",
    "    CR_Trials_ICML.append((T, cummulative_regret_list))\n",
    "    \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFINITE-ACTION SETTING\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "#     print('Trial:', T)\n",
    "    \n",
    "    action_set = A[T]\n",
    "    noise_T = noise_list[T]\n",
    "    \n",
    "    B_hat = np.zeros((d, k))\n",
    "    W_hat = np.zeros((k, M))\n",
    "    Theta_hat = B_hat.dot(W_hat)\n",
    "    \n",
    "    cumulative_regret = 0\n",
    "    cummulative_regret_list = [0]\n",
    "    \n",
    "    M_hat = np.zeros((d, d))\n",
    "    \n",
    "    X = [np.empty((d, epoch_iter)) for _ in range(M)]\n",
    "    Y = [np.empty(epoch_iter) for _ in range(M)]\n",
    "    \n",
    "    for t in tqdm(range(epoch_iter), desc = 'exploration iterations'):\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            action = action_exploration_list[t][i]\n",
    "            reward = action_set[t, i][action].dot(Theta[T][:, i])\n",
    "            cumulative_regret += np.max(action_set[t, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "            X[i][:, t] = action_set[t, i][action].reshape(-1)\n",
    "            Y[i][t] = reward + noise_T[t, i]\n",
    "            \n",
    "            M_hat = M_hat + (reward + noise_T[t, i]) ** 2 * np.dot(action_set[t, i][action].reshape(-1, 1), action_set[t, i][action].reshape(1, -1))\n",
    "            \n",
    "        cummulative_regret_list.append(cumulative_regret)\n",
    "            \n",
    "    M_hat = M_hat / (epoch_iter * M)\n",
    "    M_hat = M_hat.astype(np.float64)\n",
    "    U, Sigma, V = np.linalg.svd(M_hat, full_matrices=False)\n",
    "    B_hat = U[:, :k]\n",
    "    \n",
    "    for i in range(M):\n",
    "        \n",
    "        W_hat[:, i] = np.linalg.lstsq(np.dot(X[i].T, B_hat), Y[i], rcond = None)[0]\n",
    "        \n",
    "    Theta_hat = B_hat.dot(W_hat)\n",
    "    \n",
    "    for t in tqdm(range(epoch_iter, iterations), desc = 'commit iterations'):\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            context = Context_idx[t]\n",
    "            \n",
    "            action = np.argmax(np.dot(action_set[context, i], Theta_hat[:, i]))\n",
    "            reward = action_set[context, i][action].dot(Theta[T][:, i])\n",
    "            cumulative_regret += np.max(action_set[context, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "#             action = np.argmax(np.dot(action_set[t, i], Theta_hat[:, i]))\n",
    "#             reward = action_set[t, i][action].dot(Theta[T][:, i])\n",
    "#             cumulative_regret += np.max(action_set[t, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "        cummulative_regret_list.append(cumulative_regret)\n",
    "        \n",
    "#         print('t: {} regret: {} error: {}:'.format(num, regret, error))\n",
    "\n",
    "    CR_Trials_E2TC.append((T, cummulative_regret_list))\n",
    "    \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a057dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Approach\n",
    "start = time.time()\n",
    "\n",
    "for T in range(trials):\n",
    "    \n",
    "#     print('Trial:', T)\n",
    "    \n",
    "    action_set = A[T]\n",
    "    noise_T = noise_list[T]\n",
    "    \n",
    "    W = np.zeros((M, d, d))\n",
    "    U = np.zeros((M, d, 1))\n",
    "    \n",
    "    Theta_hat = np.zeros((d, M))\n",
    "    delta_prime = delta / (4 * iterations)\n",
    "    \n",
    "    cumulative_regret = 0\n",
    "    cummulative_regret_list = [0]\n",
    "    \n",
    "    for t in tqdm(range(iterations), desc = 'iterations'):\n",
    "        \n",
    "        for i in range(M):\n",
    "            \n",
    "            # sample eta\n",
    "            eta = np.random.multivariate_normal(mean = np.zeros(d), cov = np.eye(d))\n",
    "            \n",
    "            # compute RLS-estimate theta_hat and V\n",
    "            V = ld * np.eye(d) + W[i]\n",
    "            Theta_hat[:, i] = np.dot(np.linalg.inv(V), U[i]).reshape(-1)\n",
    "            \n",
    "            # compute the beta\n",
    "            beta = R * np.sqrt(2 * np.log((ld + t) ** (d / 2) * ld ** (- d / 2) / delta_prime)) + np.sqrt(ld) * np.linalg.norm(Theta_hat[:, i])\n",
    "            \n",
    "            # calculate V^{-1/2}\n",
    "            eigvals, eigvecs = np.linalg.eigh(V)\n",
    "            temp = eigvecs.dot(np.diag(1.0 / np.sqrt(eigvals))).dot(eigvecs.T)\n",
    "            \n",
    "            # compute theta_tilde\n",
    "            theta_tilde = Theta_hat[:, i] + beta * (temp.dot(eta)).reshape(-1)\n",
    "            \n",
    "            if t < epoch_iter:\n",
    "                \n",
    "                context = t\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                context = Context_idx[t]\n",
    "            \n",
    "            action = np.argmax(np.dot(action_set[context, i], theta_tilde))\n",
    "            feature = action_set[context, i][action].astype(np.float64)\n",
    "            reward = feature.dot(Theta[T][:, i])\n",
    "            cumulative_regret += np.max(action_set[context, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "#             action = np.argmax(np.dot(action_set[t, i], theta_tilde))\n",
    "#             feature = action_set[t, i][action].astype(np.float64)\n",
    "#             reward = feature.dot(Theta[T][:, i])\n",
    "#             cumulative_regret += np.max(action_set[t, i].dot(Theta[T][:, i])) - reward\n",
    "            \n",
    "            W[i] += np.dot(feature.reshape(-1, 1), feature.reshape(1, -1))\n",
    "            U[i] += feature.reshape(-1, 1) * (reward + noise_T[t, i])\n",
    "            \n",
    "        cummulative_regret_list.append(cumulative_regret)\n",
    "        \n",
    "#         print('t: {} regret: {} error: {}:'.format(num, regret, error))\n",
    "\n",
    "    CR_Trials_Naive.append((T, cummulative_regret_list))\n",
    "    \n",
    "end = time.time()\n",
    "print('Finished! The total time we use is: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551d67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_plot_data(CR_Trials, iterations, trials):\n",
    "    \n",
    "    x_value = np.array([i for i in range(iterations + 1)])\n",
    "    y_value = np.zeros(iterations + 1)\n",
    "    \n",
    "    for i in range(iterations + 1):\n",
    "        \n",
    "        for T in range(trials):\n",
    "            \n",
    "            y_value[i] += CR_Trials[T][1][i]\n",
    "            \n",
    "    y_value = y_value / trials\n",
    "            \n",
    "    return x_value, y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73550dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_proposed, y_proposed = prepare_plot_data(CR_Trials_ICML, iterations, trials)\n",
    "x_E2TC, y_E2TC = prepare_plot_data(CR_Trials_E2TC, iterations, trials)\n",
    "x_Naive, y_Naive = prepare_plot_data(CR_Trials_Naive, iterations, trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0185cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_proposed, y_proposed, color = 'r')\n",
    "plt.plot(x_E2TC, y_E2TC, color = 'b')\n",
    "plt.plot(x_Naive, y_Naive, color = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('CR_Trials_ICML.npy', np.array(CR_Trials_ICML, dtype=object))\n",
    "np.save('CR_Trials_E2TC.npy', np.array(CR_Trials_E2TC, dtype=object))\n",
    "np.save('CR_Trials_Naive.npy', np.array(CR_Trials_Naive, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32767e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
